{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ViTEHWincc9",
        "outputId": "795fe8aa-f109-430b-e20b-bf828f5dc936"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting serpapi\n",
            "  Downloading serpapi-0.1.5-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from serpapi) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->serpapi) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->serpapi) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->serpapi) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->serpapi) (2024.7.4)\n",
            "Installing collected packages: serpapi\n",
            "Successfully installed serpapi-0.1.5\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for google-search-results (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install serpapi\n",
        "!pip install -q pandas\n",
        "!pip install -q openpyxl\n",
        "!pip install -q google-search-results"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "import re\n",
        "import time\n",
        "from serpapi.google_search import GoogleSearch"
      ],
      "metadata": {
        "id": "dUGZLxK03f4x"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ[\"SERPAPI_API_KEY\"] = userdata.get('SERPAPI_API_KEY')"
      ],
      "metadata": {
        "id": "ogn2SL4L6_ri"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_google_scholar_results(query, num_results):\n",
        "    papers = []\n",
        "    params = {\n",
        "        \"engine\": \"google_scholar\",\n",
        "        \"q\": query,\n",
        "        \"api_key\": os.environ[\"SERPAPI_API_KEY\"],\n",
        "        \"start\": 0,\n",
        "        \"num\": 20  # Number of results per page\n",
        "    }\n",
        "\n",
        "    while len(papers) < num_results:\n",
        "        search = GoogleSearch(params)\n",
        "        results = search.get_dict()\n",
        "\n",
        "        if 'organic_results' not in results:\n",
        "            print(\"No more results found or API call failed.\")\n",
        "            break\n",
        "\n",
        "        papers.extend(results['organic_results'])\n",
        "        params[\"start\"] += 20  # Move to the next page\n",
        "        time.sleep(2)  # Respectful delay to avoid hitting rate limits\n",
        "\n",
        "        if len(results['organic_results']) < 20:\n",
        "            break  # Stop if fewer results are returned than requested per page\n",
        "\n",
        "    return papers[:num_results]"
      ],
      "metadata": {
        "id": "iQarNWInCAaj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_results(results):\n",
        "    papers = []\n",
        "\n",
        "    for result in results:\n",
        "        title = result.get('title', 'N/A')\n",
        "        authors = result.get('publication_info', {}).get('authors', [])\n",
        "        citation = result.get('inline_links', {}).get('cited_by', {}).get('total', 'N/A')\n",
        "        url = result.get('link', 'N/A')\n",
        "        abstract = result.get('snippet', 'N/A')\n",
        "        doi = result.get('inline_links', {}).get('doi', 'N/A')\n",
        "\n",
        "        authors_str = ', '.join([author.get('name', 'N/A') for author in authors])\n",
        "\n",
        "        papers.append({\n",
        "            'Title': title,\n",
        "            'Authors': authors_str,\n",
        "            'Citations': int(citation) if citation != 'N/A' else 0,\n",
        "            'URL': url,\n",
        "            'Abstract': abstract,\n",
        "            'DOI': doi\n",
        "        })\n",
        "\n",
        "    return papers"
      ],
      "metadata": {
        "id": "oLDgNHh54eRU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_file_name(query):\n",
        "    # Remove special characters\n",
        "    sanitized_query = re.sub(r'[^\\w\\s]', '', query)\n",
        "    # Truncate to the first 20 characters\n",
        "    truncated_query = sanitized_query[:20].strip()\n",
        "    # Replace spaces with underscores\n",
        "    final_query = re.sub(r'\\s+', '_', truncated_query)\n",
        "    file_name = f\"Google_Scholar_Search_{final_query}.xlsx\"\n",
        "    return file_name"
      ],
      "metadata": {
        "id": "AcXA-h3G-DKE"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_to_excel(papers, filename):\n",
        "    if not papers:\n",
        "        print(\"No papers to save.\")\n",
        "        return\n",
        "\n",
        "    # Sort papers by citations (most to least)\n",
        "    papers = sorted(papers, key=lambda x: x['Citations'], reverse=True)\n",
        "\n",
        "    df = pd.DataFrame(papers)\n",
        "    df.to_excel(filename, index=False)\n",
        "\n",
        "    print(f\"Saved {len(papers)} papers to {filename}\")"
      ],
      "metadata": {
        "id": "U30Fjdd15l0M"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    query = input(\"Enter your search query: \")\n",
        "    num_results = int(input(\"Enter the number of results you want to fetch: \"))\n",
        "    print(\"Fetching results...\")\n",
        "\n",
        "    results = fetch_google_scholar_results(query, num_results)\n",
        "    print(f\"Fetched {len(results)} results.\")\n",
        "\n",
        "    if not results:\n",
        "        print(\"No results found or API call failed.\")\n",
        "        return\n",
        "\n",
        "    print(\"Processing results...\")\n",
        "\n",
        "    papers = process_results(results)\n",
        "    print(\"Saving results to Excel...\")\n",
        "\n",
        "    file_name = generate_file_name(query)\n",
        "    save_to_excel(papers, file_name)\n",
        "    print(\"Done!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xo-lMz4-5pIo",
        "outputId": "65553f9e-30ea-444d-92ac-d12cd0636c52"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your search query: (\"pull request\" OR \"pull requests\") AND \"GitHub repository\" AND (impact OR \"code quality\" OR collaboration)\n",
            "Enter the number of results you want to fetch: 50\n",
            "Fetching results...\n",
            "Fetched 50 results.\n",
            "Processing results...\n",
            "Saving results to Excel...\n",
            "Saved 50 papers to Google_Scholar_Search_pull_request_OR_pull.xlsx\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1pSF9XuJDY4v"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "foZmEvm1EJy-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}